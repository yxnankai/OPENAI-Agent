#!/usr/bin/env python3
"""
å¢å¼ºçš„ç½‘é¡µæœç´¢å·¥å…·
èƒ½å¤Ÿè·å–æœç´¢ç»“æœå¹¶ä½¿ç”¨AIè¿›è¡Œæ€»ç»“
"""
import requests
from bs4 import BeautifulSoup
import urllib.parse
from typing import List, Dict, Any
import time
import random

class EnhancedWebSearch:
    """å¢å¼ºçš„ç½‘é¡µæœç´¢å·¥å…·"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        })
    
    def search_duckduckgo(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """ä½¿ç”¨DuckDuckGoæœç´¢"""
        try:
            search_url = f"https://duckduckgo.com/html/?q={urllib.parse.quote(query)}"
            response = self.session.get(search_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            # DuckDuckGoæœç´¢ç»“æœé€‰æ‹©å™¨
            search_results = soup.find_all('div', class_='result')
            
            for result in search_results[:max_results]:
                try:
                    # æå–æ ‡é¢˜
                    title_elem = result.find('a', class_='result__a')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    url = title_elem.get('href', '')
                    
                    # æå–æ‘˜è¦
                    snippet_elem = result.find('a', class_='result__snippet')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    # æå–æ›´å¤šå†…å®¹
                    content_elem = result.find('div', class_='result__body')
                    content = content_elem.get_text(strip=True) if content_elem else ""
                    
                    if title and snippet:
                        results.append({
                            'title': title,
                            'snippet': snippet,
                            'content': content,
                            'url': url,
                            'source': 'DuckDuckGo'
                        })
                        
                except Exception:
                    continue
            
            return results
            
        except Exception as e:
            print(f"DuckDuckGoæœç´¢å¤±è´¥: {e}")
            return []
    
    def search_bing(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """ä½¿ç”¨Bingæœç´¢"""
        try:
            search_url = f"https://www.bing.com/search?q={urllib.parse.quote(query)}"
            response = self.session.get(search_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            search_results = soup.find_all('li', class_='b_algo')
            
            for result in search_results[:max_results]:
                try:
                    title_elem = result.find('h2')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    
                    snippet_elem = result.find('p')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    if title and snippet:
                        results.append({
                            'title': title,
                            'snippet': snippet,
                            'content': snippet,
                            'url': '',
                            'source': 'Bing'
                        })
                        
                except Exception:
                    continue
            
            return results
            
        except Exception as e:
            print(f"Bingæœç´¢å¤±è´¥: {e}")
            return []
    
    def search_baidu(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """ä½¿ç”¨ç™¾åº¦æœç´¢"""
        try:
            search_url = f"https://www.baidu.com/s?wd={urllib.parse.quote(query)}"
            response = self.session.get(search_url, timeout=15)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.text, 'html.parser')
            results = []
            
            search_results = soup.find_all('div', class_='result')
            
            for result in search_results[:max_results]:
                try:
                    title_elem = result.find('h3')
                    if not title_elem:
                        continue
                    
                    title = title_elem.get_text(strip=True)
                    
                    snippet_elem = result.find('div', class_='c-abstract')
                    snippet = snippet_elem.get_text(strip=True) if snippet_elem else ""
                    
                    if title and snippet:
                        results.append({
                            'title': title,
                            'snippet': snippet,
                            'content': snippet,
                            'url': '',
                            'source': 'Baidu'
                        })
                        
                except Exception:
                    continue
            
            return results
            
        except Exception as e:
            print(f"ç™¾åº¦æœç´¢å¤±è´¥: {e}")
            return []
    
    def search_multiple_sources(self, query: str, max_results: int = 5) -> List[Dict[str, str]]:
        """ä»å¤šä¸ªæœç´¢å¼•æ“è·å–ç»“æœ"""
        all_results = []
        
        # å°è¯•å¤šä¸ªæœç´¢å¼•æ“
        search_methods = [
            self.search_duckduckgo,
            self.search_bing,
            self.search_baidu
        ]
        
        for search_method in search_methods:
            try:
                results = search_method(query, max_results)
                all_results.extend(results)
                
                # å¦‚æœè·å–åˆ°è¶³å¤Ÿçš„ç»“æœï¼Œå°±åœæ­¢
                if len(all_results) >= max_results * 2:
                    break
                    
                # æ·»åŠ å»¶è¿Ÿé¿å…è¢«å°
                time.sleep(random.uniform(1, 3))
                
            except Exception as e:
                print(f"æœç´¢æ–¹æ³• {search_method.__name__} å¤±è´¥: {e}")
                continue
        
        # å»é‡å¹¶é™åˆ¶ç»“æœæ•°é‡
        unique_results = []
        seen_titles = set()
        
        for result in all_results:
            if result['title'] not in seen_titles:
                unique_results.append(result)
                seen_titles.add(result['title'])
                
                if len(unique_results) >= max_results:
                    break
        
        return unique_results
    
    def format_search_results(self, results: List[Dict[str, str]], query: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        if not results:
            return f"ğŸŒ æœç´¢ '{query}' çš„ç»“æœ:\n\næš‚æ—¶æ— æ³•è·å–æœç´¢ç»“æœã€‚å»ºè®®æ‚¨ï¼š\n1. æ£€æŸ¥ç½‘ç»œè¿æ¥\n2. å°è¯•å…¶ä»–æœç´¢å…³é”®è¯\n3. ç›´æ¥è®¿é—®æœç´¢å¼•æ“ç½‘ç«™"
        
        result_text = f"ğŸŒ æœç´¢ '{query}' çš„ç»“æœ:\n\n"
        result_text += f"ğŸ“Š æŸ¥è¯¢å…³é”®è¯: {query}\n"
        result_text += f"ğŸ“‹ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ\n\n"
        
        # èµ„æ–™æºåˆ—è¡¨
        result_text += "ğŸ“š å‚è€ƒèµ„æ–™æº:\n"
        result_text += "=" * 50 + "\n\n"
        
        for i, result in enumerate(results, 1):
            result_text += f"ğŸ“– èµ„æ–™æº {i}:\n"
            result_text += f"   æ ‡é¢˜: {result['title']}\n"
            result_text += f"   æ¥æº: {result['source']}\n"
            if result['url']:
                result_text += f"   é“¾æ¥: {result['url']}\n"
            result_text += f"   æ‘˜è¦: {result['snippet']}\n"
            if result['content'] and result['content'] != result['snippet']:
                result_text += f"   è¯¦ç»†å†…å®¹: {result['content'][:300]}...\n"
            result_text += "\n"
        
        # æ€»ç»“éƒ¨åˆ†
        result_text += "ğŸ“ˆ æœç´¢ç»“æœæ€»ç»“:\n"
        result_text += "=" * 50 + "\n"
        
        # æå–å…³é”®ä¿¡æ¯è¿›è¡Œæ€»ç»“
        summary = self._generate_summary(results, query)
        result_text += summary
        
        return result_text
    
    def _generate_summary(self, results: List[Dict[str, str]], query: str) -> str:
        """ç”Ÿæˆæœç´¢ç»“æœæ€»ç»“"""
        if not results:
            return "æš‚æ— ç›¸å…³ä¿¡æ¯å¯æ€»ç»“ã€‚"
        
        summary = f"ğŸ” å…³äº '{query}' çš„ä¿¡æ¯æ€»ç»“:\n\n"
        
        # ä¸»è¦ä¿¡æ¯æ¥æºç»Ÿè®¡
        sources = {}
        for result in results:
            source = result['source']
            sources[source] = sources.get(source, 0) + 1
        
        summary += "ğŸ“Š ä¿¡æ¯æ¥æºåˆ†å¸ƒ:\n"
        for source, count in sources.items():
            summary += f"   â€¢ {source}: {count} æ¡ä¿¡æ¯\n"
        summary += "\n"
        
        # å…³é”®ä¿¡æ¯æå–
        summary += "ğŸ“‹ å…³é”®ä¿¡æ¯æ‘˜è¦:\n"
        key_points = []
        
        for i, result in enumerate(results[:3], 1):  # å–å‰3ä¸ªæœ€é‡è¦çš„ç»“æœ
            title = result['title']
            snippet = result['snippet']
            
            # æå–å…³é”®æ•°æ®
            if any(keyword in snippet.lower() for keyword in ['æ•°æ®', 'ç»Ÿè®¡', 'æŠ¥å‘Š', 'åˆ†æ', 'é¢„æµ‹']):
                key_points.append(f"{i}. {title} - {snippet[:100]}...")
        
        if key_points:
            for point in key_points:
                summary += f"   {point}\n"
        else:
            summary += "   æš‚æ— å…·ä½“æ•°æ®ä¿¡æ¯\n"
        
        summary += "\nğŸ’¡ å»ºè®®:\n"
        summary += "   â€¢ å»ºè®®æŸ¥çœ‹å®˜æ–¹ç»Ÿè®¡æ•°æ®è·å–å‡†ç¡®ä¿¡æ¯\n"
        summary += "   â€¢ å…³æ³¨æƒå¨æœºæ„å‘å¸ƒçš„åˆ†ææŠ¥å‘Š\n"
        summary += "   â€¢ å¯¹æ¯”å¤šä¸ªæ¥æºçš„ä¿¡æ¯ä»¥ç¡®ä¿å‡†ç¡®æ€§\n"
        summary += "   â€¢ å¦‚éœ€æ›´è¯¦ç»†ä¿¡æ¯ï¼Œå¯ç›´æ¥è®¿é—®ä¸Šè¿°é“¾æ¥\n"
        
        return summary
    
    def search_and_format(self, query: str, max_results: int = 5) -> str:
        """æœç´¢å¹¶æ ¼å¼åŒ–ç»“æœ"""
        results = self.search_multiple_sources(query, max_results)
        return self.format_search_results(results, query)

# å…¨å±€å®ä¾‹
enhanced_search = EnhancedWebSearch() 